{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SECXQd8fxWno"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2VMB_3-xdVS"
      },
      "source": [
        "#오토인코더 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t0WHuvWaxlD5"
      },
      "outputs": [],
      "source": [
        "#라이브러리 호출\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "83LgSHTmyHKw"
      },
      "outputs": [],
      "source": [
        "#MNIST 데이터셋 내려받아 전처리\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='MNIST_data/',\n",
        "                             train=True,\n",
        "                             transform=transform,\n",
        "                             download=True)\n",
        "test_dataset= datasets.MNIST(root='MNIST_data/',\n",
        "                             train=False,\n",
        "                             transform=transform,\n",
        "                             download=True)\n",
        "train_loader = DataLoader(dataset= train_dataset,\n",
        "                          batch_size=100,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True)\n",
        "test_loader = DataLoader(dataset= test_dataset,\n",
        "                          batch_size=100,\n",
        "                          shuffle=False,\n",
        "                          drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hnN5-as2yqg2"
      },
      "outputs": [],
      "source": [
        "#네트워크 신경망 생성\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.encoder_cnn = nn.Sequential(\n",
        "        nn.Conv2d(1,8,3, stride = 2, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(8,16,3, stride = 2, padding = 1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(16,32,3, stride = 2, padding = 0),\n",
        "        nn.ReLU(True)\n",
        "    ) #이미지 데이터셋 처리를 위해 합성곱 신경망 이용\n",
        "\n",
        "    self.flatten = nn.Flatten(start_dim=1)\n",
        "    self.encoder_lin = nn.Sequential(\n",
        "        nn.Linear(3 * 3 * 32, 128),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(128, encoded_space_dim)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.encoder_cnn(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.encoder_lin(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "    super().__init__()\n",
        "    self.decoder_lin = nn.Sequential(\n",
        "        nn.Linear(encoded_space_dim, 128),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(128, 3 * 3 * 32),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.unflatten = nn.Unflatten(dim=1,\n",
        "                                  unflattened_size=(32, 3, 3))\n",
        "    self.decoder_conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(8),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
        "    ) #인코더의 합성층에 대응\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.decoder_lin(x)\n",
        "      x = self.unflatten(x)\n",
        "      x = self.decoder_conv(x)\n",
        "      x = torch.sigmoid(x)\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vj947caB1XfK"
      },
      "outputs": [],
      "source": [
        "#손실 함수의 옵티마이저 지정\n",
        "\n",
        "encoder = Encoder(encoded_space_dim=4, fc2_input_dim=128)\n",
        "decoder = Decoder(encoded_space_dim=4, fc2_input_dim=128)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "params_to_optimize = [\n",
        "    {'params': encoder.parameters()},\n",
        "    {'params': decoder.parameters()}\n",
        "] #인코더와 디코더에서 사용할 파라미터를 다르게 지정\n",
        "\n",
        "optim = torch.optim.Adam(params_to_optimize, lr=0.001, weight_decay=1e-05)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qDcczWqr2CV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#모델 학습 함수 생성\n",
        "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer, noise_factor=0.3):\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "  train_loss = []\n",
        "  for image_batch, _ in dataloader: #훈련 데이터셋으로 모델 학습(비지도 학습)\n",
        "    image_noisy = add_noise(image_batch, noise_factor)\n",
        "    image_noisy = image_noisy.to(device)\n",
        "    encoded_data = encoder(image_noisy)\n",
        "    decoded_data = decoder(encoded_data)\n",
        "    loss = loss_fn(decoded_data, image_noisy)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.detach().cpu().numpy())\n",
        "  return np.mean(train_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lK03DlGE-nIc"
      },
      "outputs": [],
      "source": [
        "#모델 테스트 함수 생성\n",
        "\n",
        "def test_epoch(encoder, decoder, device, dataloader, loss_fn, noise_factor=0.3):\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    conc_out = [] #각 배치에 대한 출력을 저장하기 위해 리스트 형식의 변수 정의\n",
        "    conc_label = []\n",
        "    for image_batch, _ in dataloader:\n",
        "      image_batch = image_batch.to(device)\n",
        "      encoded_data = encoder(image_batch)\n",
        "      decoded_data = decoder(encoded_data)\n",
        "      conc_out.append(decoded_data.cpu())\n",
        "      conc_label.append(image_batch.cpu())\n",
        "    conc_out = torch.cat(conc_out) #리스트 형식으로 저장된 모든 값을 하나의 텐서로 저장\n",
        "    conc_label = torch.cat(conc_label)\n",
        "    val_loss = loss_fn(conc_out, conc_label) #손실 함수를 이용해 오차 계산\n",
        "  return val_loss.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UdBQMHai-syb"
      },
      "outputs": [],
      "source": [
        "#노이즈 데이터 생성\n",
        "\n",
        "def add_noise(inputs, noise_factor=0.3):\n",
        "  noisy = inputs + torch.randn_like(inputs) * noise_factor\n",
        "  noisy = torch.clip(noisy, 0., 1.)\n",
        "  return noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "rsx85pjFBNgc",
        "outputId": "e068877f-7d2f-4b45-fb56-9e03b17acc0b"
      },
      "outputs": [],
      "source": [
        "#한글 꺠짐\n",
        "\n",
        "from matplotlib import font_manager\n",
        "font_fname = 'C:/Windows/Fonts/malgun.ttf'\n",
        "font_family = font_manager.FontProperties(fname=font_fname).get_name()\n",
        "plt.rcParams[\"font.family\"] = font_family"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3xvB9S6QCUfE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.rcParams['font.family'] = 'NanumGothic'  # Colab 기본 제공\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zE6XtPkZCWsg"
      },
      "outputs": [],
      "source": [
        "#이미지 시각화\n",
        "\n",
        "def plot_ae_outputs(encoder, decoder, n=5, noise_factor=0.3):\n",
        "  plt.figure(figsize=(10,4.5))\n",
        "  for i in range(n):\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    img = test_dataset[i][0].unsqueeze(0)\n",
        "    image_noisy = add_noise(img, noise_factor)\n",
        "    image_noisy = image_noisy.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      rec_img = decoder(encoder(image_noisy))\n",
        "\n",
        "    plt.imshow(img.cpu().sqeeze().numpy(), cmap='gist_gray') #테스트 데이터셋 출력\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if i == n//2:\n",
        "      ax.set_title('원래 이미지')\n",
        "\n",
        "    ax = plt.subplot(3, n, i+1+n)\n",
        "    plt.imshow(image_noisy.cpu().squeeze().numpy(), cmap='gist_gray') #테스트 데이터셋에 노이즈가 적용된 결과\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if i == n//2:\n",
        "      ax.set_title('노이즈가 적용되어 손상되 이미지')\n",
        "\n",
        "    ax = plt.subplot(3, n, i+1+n+n)\n",
        "    plt.imshow(rec_img.cpu().sqeeze().numpy(), cmap='gist_gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    if i == n//2:\n",
        "      ax.set_title('재구성된 이미지')\n",
        "  plt.subplots_adjust(left=0.1, bottom=0.1, right=0.7, top=0.9, wspace=0.3, hspace=0.3)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uJ6h-UuvFb0u",
        "outputId": "e86ba929-deae-4493-8917-a3abaad263b3"
      },
      "outputs": [],
      "source": [
        "#모델 학습\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "num_epochs = 30\n",
        "history_da = {'train_loss':[], 'val_loss':[]}\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
        "  train_loss = train_epoch(\n",
        "      encoder = encoder,\n",
        "      decoder = decoder,\n",
        "      device = device,\n",
        "      dataloader = train_loader,\n",
        "      loss_fn = loss_fn,\n",
        "      optimizer = optim, noise_factor=0.3)\n",
        "\n",
        "  val_loss = test_epoch(\n",
        "      encoder = encoder,\n",
        "      decoder = decoder,\n",
        "      device = device,\n",
        "      dataloader = test_loader,\n",
        "      loss_fn = loss_fn, noise_factor=0.3)\n",
        "\n",
        "  history_da['train_loss'].append(train_loss)\n",
        "  history_da['val_loss'].append(val_loss)\n",
        "\n",
        "  print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch+1, num_epochs, train_loss, val_loss))\n",
        "plot_ae_output(encoder, decoder, noise_factor=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RJgY-3xJiA1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
