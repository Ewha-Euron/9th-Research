{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StJgA5adfgDq",
        "outputId": "42826d87-268c-4fb9-bbdb-f2922cae16f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.225-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.225-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.225 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwo_vs8kfFad",
        "outputId": "e3e17a91-ac41-4779-e211-e494bda0a053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-pose.pt to '../models/yolov8m-pose.pt': 100% ━━━━━━━━━━━━ 50.8MB 35.9MB/s 1.4s\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model = YOLO(\"../models/yolov8m-pose.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 돌렸는데.. 파일 용량이 너무 커져서 github 업로드가 불가해져 실행 결과 지웠어요...\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "# 비디오 파일을 불러오기 위한 VideoCapture 객체 생성\n",
        "capture = cv2.VideoCapture(\"./woman.mp4\")\n",
        "while cv2.waitKey(10) < 0:\n",
        "    # 현재 프레임이 전체 프레임 수와 같으면 (즉, 영상 끝에 도달하면)\n",
        "    # 다시 0번 프레임으로 되돌려서 루프 재생\n",
        "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "        capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    # 비디오로부터 한 프레임 읽기\n",
        "    ret, frame = capture.read()\n",
        "    cv2_imshow(frame)\n",
        "# 자원 해제: 비디오 객체 릴리즈\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoyKxKXkfdMG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def predict(frame, iou=0.7, conf=0.25):\n",
        "    # 모델에 프레임 입력하여 추론 실행\n",
        "    # source: 입력 이미지 또는 프레임\n",
        "    # device: GPU가 있으면 \"0\", 없으면 CPU 사용\n",
        "    # iou: Non-Maximum Suppression 시 IOU 임계값\n",
        "    # conf: 탐지 confidence 임계값\n",
        "    # verbose=False: 콘솔 출력 억제\n",
        "    results = model(\n",
        "        source=frame,\n",
        "        device=\"0\" if torch.cuda.is_available() else \"cpu\",\n",
        "        iou=0.7,\n",
        "        conf=0.25,\n",
        "        verbose=False,\n",
        "    )\n",
        "     # YOLO는 batch 제출을 가정하므로 results[0]이 첫 번째 결과\n",
        "    result = results[0]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L9GC1Kpf0VN"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(result, frame):\n",
        "  # YOLO 탐지 결과(result.boxes)에 포함된 박스들을 순회\n",
        "    for boxes in result.boxes:\n",
        "      # 각 박스 정보: x1, y1, x2, y2, score, class_index\n",
        "      # tensor -> numpy 로 변환하여 좌표와 점수를 추출\n",
        "        x1, y1, x2, y2, score, classes = boxes.data.squeeze().cpu().numpy()\n",
        "        # 탐지된 객체의 경계 상자를 원본 프레임에 그림\n",
        "        # (x1, y1): 좌측 상단, (x2, y2): 우측 하단\n",
        "        # 색상: 빨강(BGR = 0,0,255), 두께 1\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 1)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLWtjJc5f0nk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "capture = cv2.VideoCapture(\"./woman.mp4\")\n",
        "while cv2.waitKey(10) < 0:\n",
        "    # 현재 프레임이 비디오의 총 프레임 수와 같으면 (즉, 영상 끝에 도달하면)\n",
        "    # 다시 0번 프레임으로 되돌려서 무한 반복 재생\n",
        "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "        capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "    ret, frame = capture.read()\n",
        "    # 프레임을 YOLO 모델에 넣어 객체 탐지 수행\n",
        "    result = predict(frame)\n",
        "    # 탐지된 bounding box를 프레임 위에 그림\n",
        "    frame = draw_boxes(result, frame)\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNfk4-Tpf2zt"
      },
      "outputs": [],
      "source": [
        "from ultralytics.yolo.utils.plotting import Annotator\n",
        "\n",
        "# YOLO pose 결과(result)에서 keypoint를 꺼내어 프레임(frame)에 시각화하는 함수\n",
        "def draw_keypoints(result, frame):\n",
        "  # Annotator는 YOLO에서 제공하는 기본 시각화 도구 (스켈레톤 및 포인트를 그림)\n",
        "    annotator = Annotator(frame, line_width=1)\n",
        "    for kps in result.keypoints:\n",
        "        # keypoint tensor 형태 -> (num_keypoints, 3) 형태로 정리\n",
        "        # squeeze: 차원 제거, cpu 이동 준비\n",
        "        kps = kps.data.squeeze()\n",
        "        annotator.kpts(kps)\n",
        "\n",
        "        nkps = kps.cpu().numpy()\n",
        "        # nkps[:,2] = 1\n",
        "        # annotator.kpts(nkps)\n",
        "        for idx, (x, y, score) in enumerate(nkps):\n",
        "            if score > 0.5:\n",
        "                cv2.circle(frame, (int(x), int(y)), 3, (0, 0, 255), cv2.FILLED)\n",
        "                cv2.putText(frame, str(idx), (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlCLbSzqf9m9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "capture = cv2.VideoCapture(\"./woman.mp4\")\n",
        "while cv2.waitKey(10) < 0:\n",
        "    # 현재 프레임 번호가 전체 프레임 수와 같으면 (즉, 영상 끝에 도달하면)\n",
        "    # 다시 0번 프레임으로 돌아가 반복 재생\n",
        "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "        capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "    ret, frame = capture.read()\n",
        "    # YOLO 모델을 이용해 객체 탐지 및 pose keypoint 추론 수행\n",
        "    result = predict(frame)\n",
        "    frame = draw_boxes(result, frame)\n",
        "    frame = draw_keypoints(result, frame)\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
