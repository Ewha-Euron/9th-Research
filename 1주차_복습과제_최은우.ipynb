{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치 ResNet 구현"
      ],
      "metadata": {
        "id": "Wbgc7R4XBFjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QM8T25tAt_E"
      },
      "outputs": [],
      "source": [
        "#라이브러리 호출\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple #'nametuple': 파이썬의 자료형 중 하나, 인덱스값 뿐 아니라 키 값으로 데이터에 접근할 수 있게 함\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 데이터 전처리\n",
        "\n",
        "class ImageTransform():\n",
        "  def __init__(self, resize, mean, std):\n",
        "    self.data_transform = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]), #훈련 이미지 데이터에 대한 전처리\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(resize),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]) #검증 이미지 데이터에 대한 전처리\n",
        "    }\n",
        "  def __call__(self, img, phase='train'):\n",
        "    return self.data_transform[phase](img)"
      ],
      "metadata": {
        "id": "qCIZyV0jCZ80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 전처리에 사용되는 변수 값 정의\n",
        "\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "1tyjCNJ8C3DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats.zip -d dogs-vs-cats"
      ],
      "metadata": {
        "id": "UqBDnaskD6B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련/테스트셋 불러오기\n",
        "\n",
        "cat_directory = r'/content/dogs-vs-cats/Cat'\n",
        "dog_directory = r'/content/dogs-vs-cats/Dog'\n",
        "\n",
        "cat_images_filepaths = sorted([os.path.join(cat_directory, f) for f in os.listdir(cat_directory)])\n",
        "dog_images_filepaths = sorted([os.path.join(dog_directory, f) for f in os.listdir(dog_directory)])\n",
        "\n",
        "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
        "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]"
      ],
      "metadata": {
        "id": "ViFX__AeDZM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 분리\n",
        "random.seed(42)\n",
        "random.shuffle(correct_images_filepaths)\n",
        "train_images_filepaths = correct_images_filepaths[:400]\n",
        "val_images_filpaths = correct_images_filepaths[400:-10]\n",
        "test_images_filepaths = correct_images_filepaths[-10:]\n",
        "print(len(train_images_filepaths), len(val_images_filpaths), len(test_images_filepaths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3tWgDcZGxnh",
        "outputId": "c2b95004-b08e-4c72-bc41-9b02be7e934a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 92 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 레이블 구분(가져온 데이터가 개이면 '1', 고양이이면 '0')\n",
        "\n",
        "class DogvsCatDataset(Dataset):\n",
        "  def __init__(self, file_list, transform=None, phase='train'):\n",
        "    self.file_list = file_list\n",
        "    self.transform = transform\n",
        "    self.phase = phase\n",
        "  def __len__(self):\n",
        "    return len(self.file_list)\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.file_list[idx]\n",
        "    img = Image.open(img_path)\n",
        "    img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "    label = img_path.split('/')[-1].split('.')[0]\n",
        "    if label == 'dog':\n",
        "      label = 1\n",
        "    elif label == 'cat':\n",
        "      label = 0\n",
        "    return img_transformed, label\n"
      ],
      "metadata": {
        "id": "6b7oewI0INts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 데이터셋 정의\n",
        "\n",
        "train_dataset = DogvsCatDataset(file_list=train_images_filepaths, transform=ImageTransform(size, mean, std), phase='train')\n",
        "val_dataset = DogvsCatDataset(file_list=val_images_filpaths, transform=ImageTransform(size, mean, std), phase='val')\n",
        "\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLbk8g8UJwXh",
        "outputId": "d662e512-d7f0-47b7-ec5e-5bd6a3907388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋의 데이터를 메모리로 불러오기\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_iterator = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "dataloader_dict = {'train': train_iterator, 'val': val_iterator}\n",
        "\n",
        "batch_iterator = iter(train_iterator)\n",
        "inputs, label = next(batch_iterator)\n",
        "print(inputs.size())\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxe4ps_4KpLd",
        "outputId": "83e572ae-85a0-439c-bd4d-c28b66cba164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
            "        1, 0, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet 네트워크 구성"
      ],
      "metadata": {
        "id": "3mlOhk9LNZu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#기본 블록 (3x3 합성곱 2개로 구성)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    if downsample: #다운샘플링 - 입력 데이터와 출력 데이터 크기가 다른 경우\n",
        "      conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "      bn = nn.BatchNorm2d(out_channels)\n",
        "      downsample = nn.Sequential(conv, bn)\n",
        "    else:\n",
        "      downsample = None\n",
        "    self.downsample = downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "    i = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    if self.downsample is not None :\n",
        "      i = self.downsample(i)\n",
        "\n",
        "    x += I #identity mapping - 특정 층의 출력 결과를 다음 합성곱층의 출력 결과에 더함\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4h9uyxWXNTdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#병목 블록 (1x1->3x3->1x3 합성곱층)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    if downsample:\n",
        "      conv = nn.Conv2d(in_channels, out_channels*self.expansion, kernel_size=1, stride=stride, bias=False)\n",
        "      bn = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "      downsample = nn.Sequential(conv, bn)\n",
        "    else:\n",
        "      downsample = None\n",
        "    self.downsample = downsample\n",
        "  def forward(self, x):\n",
        "    i = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      i = self.downsample(i)\n",
        "\n",
        "    x += i\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "yZ4A09QmQviv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet 모델 네트워크\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, config, output_dim, zero_init_residual=False):\n",
        "    super().__init__()\n",
        "\n",
        "    block, n_blocks, channels = config #config 값들을 저장\n",
        "    self.in_channels = channels[0]\n",
        "    assert len(n_blocks) == len(channels) == 4 #assert?\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "    self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1])\n",
        "    self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2])\n",
        "    self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3])\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "    if zero_init_residual: #각 residual branck 에 있는 마지막 BN 을 0으로 초기화하여 다음 Residual 분기가 0에서 시작할 수 있도록 함\n",
        "      for m in self.modules():\n",
        "        if isinstance(m, Bottleneck):\n",
        "          nn.init.constant_(m.bn3.weight, 0)\n",
        "        elif isinstance(m, BasicBlock):\n",
        "          nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "  def get_resnet_layer(self, block, n_blocks, channels, stride=1): #블록을 추가하기 위한 함\n",
        "    layers = []\n",
        "    #다운샘플링 필요 여부 결정\n",
        "    if self.in_channels != channels * block.expansion:\n",
        "      downsample = True\n",
        "    else:\n",
        "      downsample = False\n",
        "\n",
        "    layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "    for i in range(1, n_blocks): #n_blocks 수만큼 계층 추가\n",
        "      layers.append(block(channels * block.expansion, channels))\n",
        "\n",
        "    self.in_channels = channels * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x) #224x224 (stride 2)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x) #112x112 (stride 2)\n",
        "    #residual blocks\n",
        "    x = self.layer1(x) #56x56\n",
        "    x = self.layer2(x) #28x28\n",
        "    x = self.layer3(x) #14x14\n",
        "    x = self.layer4(x) #7x7\n",
        "    x = self.avgpool(x) #1x1\n",
        "    h = x.view(x.shape[0], -1)\n",
        "    x = self.fc(h)\n",
        "    return x, h\n"
      ],
      "metadata": {
        "id": "EKsU886rR1Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNetConfig 정의\n",
        "\n",
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "metadata": {
        "id": "Gx8Nsu6Ka_SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기본 블록을 사용해서 ResNetConfig 정의\n",
        "\n",
        "resnet18_config = ResNetConfig(block=BasicBlock, n_blocks=[2, 2, 2, 2], channels=[64, 128, 256, 512])\n",
        "resnet34_config = ResNetConfig(block=BasicBlock, n_blocks=[3, 4, 6, 3], channels=[64, 128, 256, 512])\n",
        "\n",
        "#병목 블록을 사용해서 ResNetConfig 정의\n",
        "\n",
        "resnet50_config = ResNetConfig(block=Bottleneck, n_blocks=[3, 4, 6, 3], channels=[64, 128, 256, 512])\n",
        "resnet101_config = ResNetConfig(block=Bottleneck, n_blocks=[3, 4, 23, 3], channels=[64, 128, 256, 512])\n",
        "resnet152_config = ResNetConfig(block=Bottleneck, n_blocks=[3, 8, 36, 3], channels=[64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "8Mle00QJbM0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#사전 정의된 ResNet 사용"
      ],
      "metadata": {
        "id": "UgxjbbWnc8x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사전 훈련된 ResNet 모델 사용\n",
        "\n",
        "pretrained_model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8NZlzqabnMv",
        "outputId": "1730257d-6535-42a1-dbc0-bd69bc8b6758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 113MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEOC_N2Tb4On",
        "outputId": "a54f1ac5-f2ac-4628-c26a-9a348a58c136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet50 Config 를 사용한 ResNet 모델 사용\n",
        "\n",
        "OUTPUT_DIM = 2\n",
        "model = ResNet(resnet50_config, OUTPUT_DIM)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6IwqZGb84S",
        "outputId": "cce7a9fb-3523-41c4-a4ee-3ebbad5b26ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저와 손실 함수 정의\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "Nowo6HrNc4DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습 정확도 측정 함수 정의\n",
        "\n",
        "def calculate_topk_accuracy(y_pred, y, k=2):\n",
        "  with torch.no_grad():\n",
        "    batch_size = y.shape[0]\n",
        "    _, top_pred = y_pred.topk(k,1) #주어진 텐서에서 가장 큰 값의 '인덱스' 추출\n",
        "    top_pred = top_pred.t()\n",
        "    correct = top_pred.eq(y.view(1,-1).expand_as(top_pred)) #두 텐서가 같은지 확인\n",
        "    correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
        "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True) #이미지의 정확한 레이블 부여를 위해 사용\n",
        "    acc_1 = correct_1 / batch_size\n",
        "    acc_k = correct_k / batch_size\n",
        "  return acc_1, acc_k"
      ],
      "metadata": {
        "id": "ock7shTHdQg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습 함수 정의\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc_1 = 0\n",
        "  epoch_acc_5 = 0\n",
        "\n",
        "  model.train() #매 epoch 마다 학습 루프에 들어가기 전에 model.train() 을 호출해서 학습용 레이어들이 올바르게 작동되도록 함\n",
        "\n",
        "  for (x, y) in iterator:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x)\n",
        "    loss = criterion(y_pred[0], y)\n",
        "\n",
        "    acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc_1 += acc_1.item()\n",
        "    epoch_acc_5 += acc_5.item()\n",
        "\n",
        "  epoch_loss /= len(iterator)\n",
        "  epoch_acc_1 /= len(iterator)\n",
        "  epoch_acc_5 /= len(iterator)\n",
        "\n",
        "  return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "2Og75XxMeDOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 함수 정의\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc_1 = 0\n",
        "  epoch_acc_5 = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for (x, y) in iterator:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred, _ = model(x)\n",
        "\n",
        "      loss = criterion(y_pred[0], y)\n",
        "      acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc_1 += acc_1.item()\n",
        "      epoch_acc_5 += acc_5.item()\n",
        "\n",
        "      epoch_loss /= len(iterator)\n",
        "      epoch_acc_1 /= len(iterator)\n",
        "      epoch_acc_5 /= len(iterator)\n",
        "\n",
        "  return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "BSinH7uPiOpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습 시간 측정 함수\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "R_aQtwBbfiWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import lr_scheduler\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "0gaNI1zkquNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.monotonic()\n",
        "  train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
        "  valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, val_iterator, criterion, device)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "\n",
        "  end_time = time.monotonic()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(\n",
        "    f'\\t Train Loss: {train_loss:.3f} | '\n",
        "    f'Train Acc @1: {train_acc_1*100:6.2f}% | '\n",
        "    f'Train Acc @5: {train_acc_5*100:6.2f}%'\n",
        "  )\n",
        "\n",
        "  print(\n",
        "      f'\\t Val.  Loss: {valid_loss:.3f} | '\n",
        "      f'Val.  Acc @1: {valid_acc_1*100:6.2f}% | '\n",
        "      f'Val.  Acc @5: {valid_acc_5*100:6.2f}%'\n",
        "  )"
      ],
      "metadata": {
        "id": "jiLxMyUSf5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터셋을 이용한 모델 예측\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "id_list = []\n",
        "pred_list = []\n",
        "_id = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for test_path in test_images_filepaths:\n",
        "    img = Image.open(test_path)\n",
        "    _id = test_path.split('/')[-1].split('.')[1]\n",
        "    transform = ImageTransform(size, mean, std)\n",
        "    img = transform(img, phase='val')\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    outputs = model(img)\n",
        "    preds = F.softmax(outputs[0], dim=1)[:, 1].tolist()\n",
        "    id_list.append(_id)\n",
        "    pred_list.append(preds[0])\n",
        "\n",
        "res = pd.DataFrame({\n",
        "    'id': id_list,\n",
        "    'label': pred_list\n",
        "})\n",
        "\n",
        "res.sort_values(by='id', inplace=True)\n",
        "res.reset_index(drop=True, inplace=True)\n",
        "\n",
        "res.to_csv('submission.csv', index=False)\n",
        "res.head(10)"
      ],
      "metadata": {
        "id": "hMSAZN7umaqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 예측에 대한 결과 출력\n",
        "\n",
        "class_ = classes = {0:'cat', 1:'dog'}\n",
        "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
        "  rows = len(images_filepaths) // cols\n",
        "  figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "  for i, images_filepaths in enumerate(images_filepaths):\n",
        "    image = cv2.imread(image_filepath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    a = random.choice(res['id'].values)\n",
        "    label = res.loc[res['id'] == a, 'label'].values[0]\n",
        "\n",
        "    if label > 0.5:\n",
        "      label = 1\n",
        "    else:\n",
        "      label = 0\n",
        "\n",
        "    ax.ravel()[i].imshow(image)\n",
        "    ax.ravel()[i].set_title(class_[label])\n",
        "    ax.ravel()[i].set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "display_image_grid(test_images_filepaths)\n"
      ],
      "metadata": {
        "id": "5HUpcnQ8neMJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}