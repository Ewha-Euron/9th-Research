{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9wjLBPjWyEd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‘(파이토치 트랜스포머를 활용한) 자연어 처리와 컴퓨터비전 심층학습’\n",
        "범위 : p591-p599 (YOLOv8)\n"
      ],
      "metadata": {
        "id": "5vvFKCJ9XP9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOLOv8 모델로 포즈 추정(pose estimation) 수행"
      ],
      "metadata": {
        "id": "1U9Z3QiDXdhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python"
      ],
      "metadata": {
        "id": "MXQTAYTfXQzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv8 포즈 추정 모델 불러오기\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-pose.pt') #YOLO 클래스를 통해 사전 학습된 yolovim-pose 모델 불러오기\n"
      ],
      "metadata": {
        "id": "IK1Lz8_4X1mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#비디오 파일을 이용해 실시간 포즈 추정\n",
        "\n",
        "#비디오 파일 불러오기\n",
        "import cv2\n",
        "\n",
        "capture = cv2.VideoCapture(\"../datasets/woman.mp4\")\n",
        "while cv2.waitKey(10) < 0:\n",
        "  if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "    capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "  ret, frame = capture.read()\n",
        "  cv2.imshow(\"VideoFrame\", frame)\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "J1v_JoowYLPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코랩에서는 오류가 나서 아래 코드로 수정"
      ],
      "metadata": {
        "id": "NCQJNvL4ZqUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 비디오 파일을 이용해 실시간 포즈 추정\n",
        "\n",
        "# 비디오 파일 불러오기\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "capture = cv2.VideoCapture(\"/content/woman.mp4\")\n",
        "\n",
        "frame_cnt = 0  # 몇 프레임까지 볼지 제어\n",
        "\n",
        "while True:  #  키보드 입력 대신 무한 루프 + 조건 종료\n",
        "    # 마지막 프레임까지 가면 다시 처음으로\n",
        "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "        capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "    ret, frame = capture.read()\n",
        "    if not ret:   # 프레임을 못 읽으면 종료\n",
        "        break\n",
        "\n",
        "    cv2_imshow(frame)  #  cv2.imshow() 대신 사용\n",
        "\n",
        "    frame_cnt += 1\n",
        "    if frame_cnt > 200:  # 예시: 200프레임만 보고 종료\n",
        "        break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "vG6LfAZ0Zn4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os\n",
        "\n",
        "path = \"/content/woman.mp4\"\n",
        "print(os.path.exists(path))  # True여야 함\n",
        "capture = cv2.VideoCapture(path)\n",
        "print(\"Opened:\", capture.isOpened())  # True여야 함\n"
      ],
      "metadata": {
        "id": "OxsGzdT-uS8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install -y ffmpeg\n",
        "!ffmpeg -i /content/woman.mp4 -vcodec libx264 -acodec aac woman_fixed.mp4\n"
      ],
      "metadata": {
        "id": "DbUm3_YRua54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture = cv2.VideoCapture(\"woman_fixed.mp4\")\n",
        "print(\"Opened:\", capture.isOpened())\n"
      ],
      "metadata": {
        "id": "7v0zwpvDulRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 추론\n",
        "\n",
        "import torch\n",
        "\n",
        "def predict(frame, iou=0.7, conf=0.25):\n",
        "  results = model(\n",
        "      source=frame,\n",
        "      device=0 if torch.cuda.is_available() else 'cpu',\n",
        "      iou=0.7, #중복된 경계 상자를 제거하는 임곗값\n",
        "      conf=0.25, #클래스 점수 임곗값 - 이 값보다 낮은 값은 제거\n",
        "      verbose=False,#로그 정보- 모델 수행 시 출력되는 정보 표시 여부 결정\n",
        "  )\n",
        "  result = results[0]\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "ruTL2CanZ6OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#경계 상자 시각화\n",
        "\n",
        "def draw_boxes(result, frame):\n",
        "  for boxes in result.boxes:\n",
        "    x1, y1, x2, y2, score, classes = boxes.data.squeeze().cpu().numpy()\n",
        "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 1) #이미지, x, y, 색상, 선 두께\n",
        "  return frame\n"
      ],
      "metadata": {
        "id": "HYZkQsn5bUIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 추론 및 시각화 적용\n",
        "\n",
        "ret, frame = capture.read()\n",
        "result = predict(frame)\n",
        "frame = draw_boxes(result, frame)\n",
        "cv2.imshow(\"VideoFrame\", frame)\n"
      ],
      "metadata": {
        "id": "skM8DAXzoziq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 추론 및 시각화 적용\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "ret, frame = capture.read()\n",
        "\n",
        "if not ret:\n",
        "    print(\"프레임을 읽을 수 없습니다.\")\n",
        "else:\n",
        "    result = predict(frame)\n",
        "    frame = draw_boxes(result, frame)\n",
        "    cv2_imshow(frame)  # Colab에서는 cv2.imshow() 대신 이걸 사용\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "r4c8M-lQvE5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "XEW2564TvPcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#키 포인트 시각화\n",
        "\n",
        "#from ultralytics.yolo.plotting import Annotator\n",
        "from ultralytics.utils.plotting import Annotator  # 최신 버전 경로\n",
        "\n",
        "def draw_keypoints(result, frame):\n",
        "  annotator = Annotator(frame, line_width=1)\n",
        "  for kps in result.keypoints: #키 포인트 kps 는 사람의 수만큼 존재할 수 있다.\n",
        "    kps = kps.data.squeeze()\n",
        "    annotator.kpts(kps)\n",
        "    nkps = kps.cpu().numpy()\n",
        "\n",
        "    for idx, (x,y,score) in enumerate(nkps):\n",
        "      if score > 0.5:\n",
        "        cv2.circle(frame, (int(x), int(y)), 3, (0,0,255), cv2.FILLED)\n",
        "        cv2.putText(\n",
        "            frame, str(idx), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1\n",
        "        )\n",
        "  return frame"
      ],
      "metadata": {
        "id": "_wLPKyElp5aR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}